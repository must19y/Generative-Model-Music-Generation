{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOUzCfXoAL9zY+AZZCtPfd0"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j70T9_huD7oT",
        "outputId": "ad0ba8cf-eed1-4b40-f035-73155ec9bd7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  bach+chorales.zip\n",
            "  inflating: bach-chorales/Index     \n",
            "  inflating: bach-chorales/chorales.doc  \n",
            "  inflating: bach-chorales/chorales.lisp.Z  \n"
          ]
        }
      ],
      "source": [
        "!unzip bach+chorales.zip -d bach-chorales"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "\n",
        "file= os.path.join('/content/Jsb16thSeparated.npz')\n",
        "with np.load(file, encoding=\"bytes\", allow_pickle=True) as f:\n",
        "    data = f[\"train\"]\n",
        "\n"
      ],
      "metadata": {
        "id": "PUIZ83NdD-OG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N_SONGS= len(data)\n",
        "print(f\"{N_SONGS} chorales in the the dataset\")\n"
      ],
      "metadata": {
        "id": "DDTonWLeD-RF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9a39cf3-5798-4e49-86b9-2b8f3fa1e1c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "229 chorales in the the dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chorales= data[0]\n",
        "print(chorales.shape)"
      ],
      "metadata": {
        "id": "16U2OnUmD-Vf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb02bed4-1854-4ebd-e8c6-58717c17b123"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(192, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nChorale 0\")\n",
        "print(chorales[:8])\n"
      ],
      "metadata": {
        "id": "4s4cFM6U2XYX",
        "outputId": "8f6fa661-09bc-4afa-b1ab-de743011a6b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Chorale 0\n",
            "[[74. 70. 65. 58.]\n",
            " [74. 70. 65. 58.]\n",
            " [74. 70. 65. 58.]\n",
            " [74. 70. 65. 58.]\n",
            " [75. 70. 58. 55.]\n",
            " [75. 70. 58. 55.]\n",
            " [75. 70. 60. 55.]\n",
            " [75. 70. 60. 55.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Prepare the data in the shape we want by extracting and reshaping them.\n",
        "N_BARS= 2\n",
        "N_STEPS_PER_BAR= 16\n",
        "N_PITCHES= 84\n",
        "N_TRACKS= 4\n",
        "MAX_PITCH=83\n",
        "BATCH_SIZE= 64\n",
        "\n",
        "\n",
        "two_bars = np.array([x[: (N_STEPS_PER_BAR * N_BARS)] for x in data])\n",
        "two_bars = np.array(np.nan_to_num(two_bars, nan=MAX_PITCH), dtype=int)\n",
        "two_bars = two_bars.reshape([N_SONGS, N_BARS, N_STEPS_PER_BAR, N_TRACKS])\n",
        "print(f\"Two bars shape {two_bars.shape}\")\n",
        "data_binary = np.eye(N_PITCHES)[two_bars]\n",
        "data_binary[data_binary == 0] = -1\n",
        "data_binary = data_binary.transpose([0, 1, 2, 4, 3])\n",
        "print(f\"Data binary shape {data_binary.shape}\")\n"
      ],
      "metadata": {
        "id": "MMaYKxdv2Xkz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "089004e4-3c9c-4af4-be90-be08fd3d3f16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Two bars shape (229, 2, 16, 4)\n",
            "Data binary shape (229, 2, 16, 84, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Now to build a GAN  we need a temporal network too that defines how the values flow\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers,models,initializers,callbacks,metrics,optimizers\n",
        "\n",
        "Z_DIM= 32\n",
        "\n",
        "\n",
        "initializer = initializers.RandomNormal(mean=0.0, stddev=0.02)\n",
        "\n",
        "\n",
        "def conv(x, f, k, s, p):\n",
        "    x = layers.Conv3D(\n",
        "        filters=f,\n",
        "        kernel_size=k,\n",
        "        padding=p,\n",
        "        strides=s,\n",
        "        kernel_initializer=initializer,\n",
        "    )(x)\n",
        "    x = layers.LeakyReLU()(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def conv_t(x, f, k, s, a, p, bn):\n",
        "    x = layers.Conv2DTranspose(\n",
        "        filters=f,\n",
        "        kernel_size=k,\n",
        "        padding=p,\n",
        "        strides=s,\n",
        "        kernel_initializer=initializer,\n",
        "    )(x)\n",
        "    if bn:\n",
        "        x = layers.BatchNormalization(momentum=0.9)(x)\n",
        "\n",
        "    x = layers.Activation(a)(x)\n",
        "    return x\n",
        "def TemporalNetwork():\n",
        "    input_layer = layers.Input(shape=(Z_DIM,), name=\"temporal_input\")\n",
        "    x = layers.Reshape([1, 1, Z_DIM])(input_layer)\n",
        "    x = conv_t(x, f=1024, k=(2, 1), s=(1, 1), a=\"relu\", p=\"valid\", bn=True)\n",
        "    x = conv_t(\n",
        "        x, f=Z_DIM, k=(N_BARS - 1, 1), s=(1, 1), a=\"relu\", p=\"valid\", bn=True\n",
        "    )\n",
        "    output_layer = layers.Reshape([N_BARS, Z_DIM])(x)\n",
        "    return models.Model(input_layer, output_layer)\n",
        "\n",
        "\n",
        "TemporalNetwork().summary()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fHhDVe8c2XwS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "outputId": "365d6ca0-04cb-467f-8124-83c12005a32c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ temporal_input (\u001b[38;5;33mInputLayer\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ reshape (\u001b[38;5;33mReshape\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m32\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_transpose (\u001b[38;5;33mConv2DTranspose\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1024\u001b[0m)          │          \u001b[38;5;34m66,560\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1024\u001b[0m)          │           \u001b[38;5;34m4,096\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation (\u001b[38;5;33mActivation\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1024\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_transpose_1 (\u001b[38;5;33mConv2DTranspose\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m32\u001b[0m)            │          \u001b[38;5;34m32,800\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_1                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m32\u001b[0m)            │             \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_1 (\u001b[38;5;33mActivation\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m32\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ reshape_1 (\u001b[38;5;33mReshape\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m32\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ temporal_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_transpose (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">66,560</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_transpose_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">32,800</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_1                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ reshape_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m103,584\u001b[0m (404.62 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">103,584</span> (404.62 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m101,472\u001b[0m (396.38 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">101,472</span> (396.38 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,112\u001b[0m (8.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> (8.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def BarGenerator():\n",
        "    input_layer = layers.Input(shape=(Z_DIM * 4,), name=\"bar_generator_input\")\n",
        "\n",
        "    x = layers.Dense(1024)(input_layer)\n",
        "    x = layers.BatchNormalization(momentum=0.9)(x)\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "    x = layers.Reshape([2, 1, 512])(x)\n",
        "\n",
        "    x = conv_t(x, f=512, k=(2, 1), s=(2, 1), a=\"relu\", p=\"same\", bn=True)\n",
        "    x = conv_t(x, f=256, k=(2, 1), s=(2, 1), a=\"relu\", p=\"same\", bn=True)\n",
        "    x = conv_t(x, f=256, k=(2, 1), s=(2, 1), a=\"relu\", p=\"same\", bn=True)\n",
        "    x = conv_t(x, f=256, k=(1, 7), s=(1, 7), a=\"relu\", p=\"same\", bn=True)\n",
        "    x = conv_t(x, f=1, k=(1, 12), s=(1, 12), a=\"tanh\", p=\"same\", bn=False)\n",
        "\n",
        "    output_layer = layers.Reshape([1, N_STEPS_PER_BAR, N_PITCHES, 1])(x)\n",
        "\n",
        "    return models.Model(input_layer, output_layer)\n"
      ],
      "metadata": {
        "id": "1Ud0NYakb6d3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Generator():\n",
        "    chords_input = layers.Input(shape=(Z_DIM,), name=\"chords_input\")\n",
        "    style_input = layers.Input(shape=(Z_DIM,), name=\"style_input\")\n",
        "    melody_input = layers.Input(shape=(N_TRACKS, Z_DIM), name=\"melody_input\")\n",
        "    groove_input = layers.Input(shape=(N_TRACKS, Z_DIM), name=\"groove_input\")\n",
        "\n",
        "    # CHORDS -> TEMPORAL NETWORK\n",
        "    chords_tempNetwork = TemporalNetwork()\n",
        "    chords_over_time = chords_tempNetwork(chords_input)  # [n_bars, z_dim]\n",
        "\n",
        "    # MELODY -> TEMPORAL NETWORK\n",
        "    melody_over_time = [\n",
        "        None\n",
        "    ] * N_TRACKS  # list of n_tracks [n_bars, z_dim] tensors\n",
        "    melody_tempNetwork = [None] * N_TRACKS\n",
        "    for track in range(N_TRACKS):\n",
        "        melody_tempNetwork[track] = TemporalNetwork()\n",
        "        melody_track = layers.Lambda(lambda x, track=track: x[:, track, :])(\n",
        "            melody_input\n",
        "        )\n",
        "        melody_over_time[track] = melody_tempNetwork[track](melody_track)\n",
        "\n",
        "    # CREATE BAR GENERATOR FOR EACH TRACK\n",
        "    barGen = [None] * N_TRACKS\n",
        "    for track in range(N_TRACKS):\n",
        "        barGen[track] = BarGenerator()\n",
        "\n",
        "    # CREATE OUTPUT FOR EVERY TRACK AND BAR\n",
        "    bars_output = [None] * N_BARS\n",
        "    c = [None] * N_BARS\n",
        "    for bar in range(N_BARS):\n",
        "        track_output = [None] * N_TRACKS\n",
        "\n",
        "        c[bar] = layers.Lambda(lambda x, bar=bar: x[:, bar, :])(\n",
        "            chords_over_time\n",
        "        )  # [z_dim]\n",
        "        s = style_input  # [z_dim]\n",
        "\n",
        "        for track in range(N_TRACKS):\n",
        "            m = layers.Lambda(lambda x, bar=bar: x[:, bar, :])(\n",
        "                melody_over_time[track]\n",
        "            )  # [z_dim]\n",
        "            g = layers.Lambda(lambda x, track=track: x[:, track, :])(\n",
        "                groove_input\n",
        "            )  # [z_dim]\n",
        "\n",
        "            z_input = layers.Concatenate(\n",
        "                axis=1, name=\"total_input_bar_{}_track_{}\".format(bar, track)\n",
        "            )([c[bar], s, m, g])\n",
        "\n",
        "            track_output[track] = barGen[track](z_input)\n",
        "\n",
        "        bars_output[bar] = layers.Concatenate(axis=-1)(track_output)\n",
        "\n",
        "    generator_output = layers.Concatenate(axis=1, name=\"concat_bars\")(\n",
        "        bars_output\n",
        "    )\n",
        "\n",
        "    return models.Model(\n",
        "        [chords_input, style_input, melody_input, groove_input],\n",
        "        generator_output,\n",
        "    )\n",
        "\n",
        "\n",
        "generator = Generator()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "TFgbNvzZb6zB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Now lets create the critic function that outputs a score without using any activation function which will help\n",
        "## the critic understand the generated music through the generator i.e fake music .\n",
        "\n",
        "def Critic():\n",
        "    critic_input = layers.Input(\n",
        "        shape=(N_BARS, N_STEPS_PER_BAR, N_PITCHES, N_TRACKS),\n",
        "        name=\"critic_input\",\n",
        "    )\n",
        "\n",
        "    x = critic_input\n",
        "\n",
        "    x = conv(x, f=128, k=(2, 1, 1), s=(1, 1, 1), p=\"valid\")\n",
        "    x = conv(x, f=128, k=(N_BARS - 1, 1, 1), s=(1, 1, 1), p=\"valid\")\n",
        "    x = conv(x, f=128, k=(1, 1, 12), s=(1, 1, 12), p=\"same\")\n",
        "    x = conv(x, f=128, k=(1, 1, 7), s=(1, 1, 7), p=\"same\")\n",
        "    x = conv(x, f=128, k=(1, 2, 1), s=(1, 2, 1), p=\"same\")\n",
        "    x = conv(x, f=128, k=(1, 2, 1), s=(1, 2, 1), p=\"same\")\n",
        "    x = conv(x, f=256, k=(1, 4, 1), s=(1, 2, 1), p=\"same\")\n",
        "    x = conv(x, f=512, k=(1, 3, 1), s=(1, 2, 1), p=\"same\")\n",
        "\n",
        "    x = layers.Flatten()(x)\n",
        "\n",
        "    x = layers.Dense(1024, kernel_initializer=initializer)(x)\n",
        "    x = layers.LeakyReLU()(x)\n",
        "\n",
        "    critic_output = layers.Dense(\n",
        "        1, activation=None, kernel_initializer=initializer\n",
        "    )(x)\n",
        "\n",
        "    return models.Model(critic_input, critic_output)\n",
        "\n",
        "\n",
        "critic = Critic()"
      ],
      "metadata": {
        "id": "UPdjbPyt_yY5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MuseGAN(models.Model):\n",
        "    def __init__(self, critic, generator, latent_dim, critic_steps, gp_weight):\n",
        "        super(MuseGAN, self).__init__()\n",
        "        self.critic = critic\n",
        "        self.generator = generator\n",
        "        self.latent_dim = latent_dim\n",
        "        self.critic_steps = critic_steps\n",
        "        self.gp_weight = gp_weight\n",
        "\n",
        "    def compile(self, c_optimizer, g_optimizer):\n",
        "        super(MuseGAN, self).compile()\n",
        "        self.c_optimizer = c_optimizer\n",
        "        self.g_optimizer = g_optimizer\n",
        "        self.c_wass_loss_metric = metrics.Mean(name=\"c_wass_loss\")\n",
        "        self.c_gp_metric = metrics.Mean(name=\"c_gp\")\n",
        "        self.c_loss_metric = metrics.Mean(name=\"c_loss\")\n",
        "        self.g_loss_metric = metrics.Mean(name=\"g_loss\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [\n",
        "            self.c_loss_metric,\n",
        "            self.c_wass_loss_metric,\n",
        "            self.c_gp_metric,\n",
        "            self.g_loss_metric,\n",
        "        ]\n",
        "\n",
        "    def gradient_penalty(self, batch_size, real_images, fake_images):\n",
        "        alpha = tf.random.normal([batch_size, 1, 1, 1, 1], 0.0, 1.0)\n",
        "        diff = fake_images - real_images\n",
        "        interpolated = real_images + alpha * diff\n",
        "\n",
        "        with tf.GradientTape() as gp_tape:\n",
        "            gp_tape.watch(interpolated)\n",
        "            pred = self.critic(interpolated, training=True)\n",
        "\n",
        "        grads = gp_tape.gradient(pred, [interpolated])[0]\n",
        "        norm = tf.sqrt(tf.reduce_sum(tf.square(grads), axis=[1, 2, 3]))\n",
        "        gp = tf.reduce_mean((norm - 1.0) ** 2)\n",
        "        return gp\n",
        "\n",
        "    def train_step(self, real_images):\n",
        "        batch_size = tf.shape(real_images)[0]\n",
        "\n",
        "        for i in range(self.critic_steps):\n",
        "            chords_random_latent_vectors = tf.random.normal(\n",
        "                shape=(batch_size, self.latent_dim)\n",
        "            )\n",
        "            style_random_latent_vectors = tf.random.normal(\n",
        "                shape=(batch_size, self.latent_dim)\n",
        "            )\n",
        "            melody_random_latent_vectors = tf.random.normal(\n",
        "                shape=(batch_size, N_TRACKS, self.latent_dim)\n",
        "            )\n",
        "            groove_random_latent_vectors = tf.random.normal(\n",
        "                shape=(batch_size, N_TRACKS, self.latent_dim)\n",
        "            )\n",
        "\n",
        "            random_latent_vectors = [\n",
        "                chords_random_latent_vectors,\n",
        "                style_random_latent_vectors,\n",
        "                melody_random_latent_vectors,\n",
        "                groove_random_latent_vectors,\n",
        "            ]\n",
        "\n",
        "            with tf.GradientTape() as tape:\n",
        "                fake_images = self.generator(\n",
        "                    random_latent_vectors, training=True\n",
        "                )\n",
        "                fake_predictions = self.critic(fake_images, training=True)\n",
        "                real_predictions = self.critic(real_images, training=True)\n",
        "\n",
        "                c_wass_loss = tf.reduce_mean(fake_predictions) - tf.reduce_mean(\n",
        "                    real_predictions\n",
        "                )\n",
        "                c_gp = self.gradient_penalty(\n",
        "                    batch_size, real_images, fake_images\n",
        "                )\n",
        "                c_loss = c_wass_loss + c_gp * self.gp_weight\n",
        "\n",
        "            c_gradient = tape.gradient(c_loss, self.critic.trainable_variables)\n",
        "            self.c_optimizer.apply_gradients(\n",
        "                zip(c_gradient, self.critic.trainable_variables)\n",
        "            )\n",
        "\n",
        "        chords_random_latent_vectors = tf.random.normal(\n",
        "            shape=(batch_size, self.latent_dim)\n",
        "        )\n",
        "        style_random_latent_vectors = tf.random.normal(\n",
        "            shape=(batch_size, self.latent_dim)\n",
        "        )\n",
        "        melody_random_latent_vectors = tf.random.normal(\n",
        "            shape=(batch_size, N_TRACKS, self.latent_dim)\n",
        "        )\n",
        "        groove_random_latent_vectors = tf.random.normal(\n",
        "            shape=(batch_size, N_TRACKS, self.latent_dim)\n",
        "        )\n",
        "\n",
        "        random_latent_vectors = [\n",
        "            chords_random_latent_vectors,\n",
        "            style_random_latent_vectors,\n",
        "            melody_random_latent_vectors,\n",
        "            groove_random_latent_vectors,\n",
        "        ]\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            fake_images = self.generator(random_latent_vectors, training=True)\n",
        "            fake_predictions = self.critic(fake_images, training=True)\n",
        "            g_loss = -tf.reduce_mean(fake_predictions)\n",
        "\n",
        "        gen_gradient = tape.gradient(g_loss, self.generator.trainable_variables)\n",
        "        self.g_optimizer.apply_gradients(\n",
        "            zip(gen_gradient, self.generator.trainable_variables)\n",
        "        )\n",
        "\n",
        "        self.c_loss_metric.update_state(c_loss)\n",
        "        self.c_wass_loss_metric.update_state(c_wass_loss)\n",
        "        self.c_gp_metric.update_state(c_gp)\n",
        "        self.g_loss_metric.update_state(g_loss)\n",
        "\n",
        "        return {m.name: m.result() for m in self.metrics}\n",
        "\n",
        "    def generate_piano_roll(self, num_scores):\n",
        "        chords_random_latent_vectors = tf.random.normal(\n",
        "            shape=(num_scores, Z_DIM)\n",
        "        )\n",
        "        style_random_latent_vectors = tf.random.normal(\n",
        "            shape=(num_scores, Z_DIM)\n",
        "        )\n",
        "        melody_random_latent_vectors = tf.random.normal(\n",
        "            shape=(num_scores, N_TRACKS, Z_DIM)\n",
        "        )\n",
        "        groove_random_latent_vectors = tf.random.normal(\n",
        "            shape=(num_scores, N_TRACKS, Z_DIM)\n",
        "        )\n",
        "        random_latent_vectors = [\n",
        "            chords_random_latent_vectors,\n",
        "            style_random_latent_vectors,\n",
        "            melody_random_latent_vectors,\n",
        "            groove_random_latent_vectors,\n",
        "        ]\n",
        "        generated_music = self.generator(random_latent_vectors)\n",
        "        generated_music = generated_music.numpy()\n",
        "        return generated_music"
      ],
      "metadata": {
        "id": "b_0mgim4_yd5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CRITIC_STEPS = 5\n",
        "GP_WEIGHT = 10\n",
        "CRITIC_LEARNING_RATE = 0.001\n",
        "GENERATOR_LEARNING_RATE = 0.001\n",
        "ADAM_BETA_1 = 0.5\n",
        "ADAM_BETA_2 = 0.9\n",
        "\n",
        "\n",
        "musegan = MuseGAN(\n",
        "    critic=critic,\n",
        "    generator=generator,\n",
        "    latent_dim=Z_DIM,\n",
        "    critic_steps=CRITIC_STEPS,\n",
        "    gp_weight=GP_WEIGHT,\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "bTBgD1i9_yk3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the GAN\n",
        "musegan.compile(\n",
        "    c_optimizer=optimizers.Adam(\n",
        "        learning_rate=CRITIC_LEARNING_RATE,\n",
        "        beta_1=ADAM_BETA_1,\n",
        "        beta_2=ADAM_BETA_2,\n",
        "    ),\n",
        "    g_optimizer=optimizers.Adam(\n",
        "        learning_rate=GENERATOR_LEARNING_RATE,\n",
        "        beta_1=ADAM_BETA_1,\n",
        "        beta_2=ADAM_BETA_2,\n",
        "    ),\n",
        ")"
      ],
      "metadata": {
        "id": "waT9laHy_ysj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Now training the data for musegan since musegan doesn't have its own fit method\n"
      ],
      "metadata": {
        "id": "4J3JxhNoRWoV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices(tf.cast(data_binary, tf.float32))\n",
        "dataset = dataset.shuffle(buffer_size=len(data_binary)).batch(BATCH_SIZE)\n",
        "\n",
        "EPOCHS = 1  ## taking here less no. of epochs due to lack of time and computation power take 100 orso\n",
        "\n",
        "# Looping  over epochs\n",
        "for epoch in range(EPOCHS):\n",
        "    print(f\"Epoch {epoch + 1}/{EPOCHS}\")\n",
        "\n",
        "    for step, real_images in enumerate(dataset):\n",
        "        loss_dict = musegan.train_step(real_images)\n",
        "\n",
        "        if step % 100 == 0:\n",
        "            print(f\"Step {step}: Critic Loss = {loss_dict['c_loss']:.4f}, \"\n",
        "                  f\"Generator Loss = {loss_dict['g_loss']:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "d-2eYDM7RWto",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5e8b452-fd4a-4e37-a8fa-bf1dd1df91d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1\n",
            "Step 0: Critic Loss = -727.3561, Generator Loss = -135.0367\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_scores = 4 ## generation of music samples by specifying num_scores\n",
        "generated_music = musegan.generate_piano_roll(num_scores)\n"
      ],
      "metadata": {
        "id": "xJBr7NyURWyZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Now to use play midi library to save the music in the specified file path  as a midi file\n",
        "\n",
        "!pip install pretty_midi\n",
        "import pretty_midi\n",
        "\n",
        "def piano_roll_to_midi(piano_roll, file_path):\n",
        "    midi = pretty_midi.PrettyMIDI()\n",
        "    instrument = pretty_midi.Instrument(program=0)\n",
        "\n",
        "\n",
        "    for time, pitches in enumerate(piano_roll):\n",
        "        for pitch, value in enumerate(pitches):\n",
        "            if value.any():  # If there's a note\n",
        "                note = pretty_midi.Note(\n",
        "                    velocity=100,\n",
        "                    pitch=pitch+21,\n",
        "                    start=time * 0.5,\n",
        "                    end=(time + 1) * 0.5\n",
        "                )\n",
        "                instrument.notes.append(note)\n",
        "\n",
        "    midi.instruments.append(instrument)\n",
        "    midi.write(file_path)\n",
        "\n",
        "# Save the first generated score as a MIDI file\n",
        "piano_roll = generated_music[0]\n",
        "piano_roll_to_midi(piano_roll, \"/content/generated_score.mid\")\n",
        "\n"
      ],
      "metadata": {
        "id": "VUXC_J5mRW26",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2d36406-361f-4038-d8bf-0d84f77ee41a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pretty_midi in /usr/local/lib/python3.10/dist-packages (0.2.10)\n",
            "Requirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from pretty_midi) (1.26.4)\n",
            "Requirement already satisfied: mido>=1.1.16 in /usr/local/lib/python3.10/dist-packages (from pretty_midi) (1.3.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from pretty_midi) (1.16.0)\n",
            "Requirement already satisfied: packaging~=23.1 in /usr/local/lib/python3.10/dist-packages (from mido>=1.1.16->pretty_midi) (23.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import pygame\n",
        "\n",
        "#def play_midi(file_path):   As we are using colab pygame cant be used to play the files so instead we convert into wav format and download it\n",
        "    # Initialize Pygame mixer\n",
        " #   pygame.mixer.init()\n",
        "   # pygame.mixer.music.load(file_path)\n",
        "    #pygame.mixer.music.play()\n",
        "\n",
        "    #while pygame.mixer.music.get_busy():  # Wait until playback finishes\n",
        "     #   pygame.time.Clock().tick(10)\n",
        "\n",
        "#play_midi(\"/content/generated_score.mid\")\n"
      ],
      "metadata": {
        "id": "UmBtGy7NRW_w",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "cc277fc3-cd2e-4256-e55b-1506d5acd8dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "ALSA: Couldn't open audio device: No such file or directory",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-690d6d969faa>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mpygame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mClock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtick\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mplay_midi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/generated_score.mid\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-23-690d6d969faa>\u001b[0m in \u001b[0;36mplay_midi\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplay_midi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# Initialize Pygame mixer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mpygame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmixer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mpygame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmixer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmusic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mpygame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmixer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmusic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: ALSA: Couldn't open audio device: No such file or directory"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pretty_midi\n",
        "from pydub import AudioSegment\n",
        "import numpy as np\n",
        "\n",
        "def midi_to_wav(midi_path, wav_path):\n",
        "    # Load the MIDI file\n",
        "    midi_data = pretty_midi.PrettyMIDI(midi_path)\n",
        "\n",
        "    audio_data = midi_data.synthesize(fs=44100)\n",
        "\n",
        "    # Converting float32 array to int16 array\n",
        "    audio_data = np.int16(audio_data / np.max(np.abs(audio_data)) * 32767)\n",
        "\n",
        "    audio_segment = AudioSegment(\n",
        "        audio_data.tobytes(),\n",
        "        frame_rate=44100,\n",
        "        sample_width=2,\n",
        "        channels=1\n",
        "    )\n",
        "\n",
        "    # Exporting as a WAV file\n",
        "    audio_segment.export(wav_path, format=\"wav\")\n",
        "\n",
        "# Converting the MIDI to WAV\n",
        "midi_to_wav(\"/content/generated_score.mid\", \"/content/generated_score.wav\")\n"
      ],
      "metadata": {
        "id": "zMxd0Dd0qKAq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/generated_score.wav\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "HJfo2lQmqKWg",
        "outputId": "19c0e73a-c7ab-410b-dab1-3265bd62e7ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_8b11b21e-8927-4ee3-a72b-008177b44cda\", \"generated_score.wav\", 176444)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1XNaaVTSqKl_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LO31CCBwqK0E"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}